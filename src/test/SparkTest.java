package test;


//import org.apache.spark.SparkConf;
//import org.apache.spark.SparkContext;
//import org.apache.spark.api.java.JavaPairRDD;
//import org.apache.spark.api.java.JavaRDD;
//import org.apache.spark.api.java.JavaSparkContext;
//import org.apache.spark.api.java.function.FlatMapFunction;
//import org.apache.spark.api.java.function.Function;
//import org.apache.spark.rdd.MapPartitionsRDD;
//import org.apache.spark.streaming.Duration;
//import org.apache.spark.streaming.StreamingContext;
//import org.apache.spark.streaming.dstream.DStream;
import scala.reflect.ClassTag;
import scala.reflect.ClassTag$;

import java.util.Arrays;
import java.util.HashSet;
import java.util.List;
import java.util.concurrent.ExecutionException;

/**
 * Created by like on 8/5/15.
 */
public class SparkTest {
    public static void main(String[] args) {
//        String appName = "app1";
//        String master = "spark://localhost:7077";
//        master = "local[2]";
//        SparkConf conf = new SparkConf().setAppName(appName).setMaster(master);
//        StreamingContext scc = new StreamingContext(conf, new Duration(1));



    }
}
